Diffusion-LM Improves Controllable Text Generation

1. 논문이 나오게 된 배경
기존 Autoregressive Language Models (AR-LMs)는 고품질 텍스트 생성을 잘하지만, 제어 가능한 텍스트 생성에는 한계가 있음.
특히, 단순한 속성(예: 감정, 주제) 제어는 가능하나, 구문 구조나 길이 같은 복잡하고 정밀한 제어는 어려움.
Fine-tuning 기반 방식은 제어가 가능하나, 각 제어마다 별도 학습이 필요하고 조합 제어가 어려움.
이에 따라, 기존 LM을 그대로 유지하며 플러그-앤-플레이 방식으로 제어가 가능한 새로운 접근이 요구됨.
이미지, 오디오 분야에서 성공한 Diffusion Model을 텍스트에 적용하여 이 문제를 해결하려는 시도가 본 논문의 핵심 동기.
플러그-앤-플레이 방식: 언어 모델(예: GPT)을 새로 훈련하지 않고, 이미 훈련된 모델에 외부 조정 모듈(classifier 등)을 붙여서 제어하는 방식

2. 아키텍처 설명
Diffusion-LM은 연속 확산 모델을 기반으로 함. Gaussian noise에서 시작하여 점진적으로 단어 임베딩 벡터로 denoise.

각 단계의 중간 표현은 연속적인 latent를 형성하며, 이 위에서 gradient-based control을 수행.

주요 구성 요소:
Embedding Function: 단어를 연속 벡터로 매핑.
각 단어를 임베딩 벡터로 바꾸고 이 벡터에 Gaussian noise를 점진적으로 추가
초기에는 완전한 Gaussian noise로 시작하고, 시간에 따라 점점 denoise하여 임베딩 벡터에 가까워지게 함
마지막에는 이 continuous 벡터를 다시 discrete 단어로 rounding 해서 텍스트 복원

Clamping Trick: 예측된 벡터를 가장 가까운 단어 임베딩으로 정제하여 rounding 오류를 줄임.

제어는 classifier-guided gradient descent로 latent 변수에 직접 적용함.
Diffusion-LM은 연속적인 벡터 공간(word embedding space)에서 동작하므로, 최종적으로 얻은 벡터 
는 "단어" 그 자체가 아니라 어떤 단어의 임베딩 근처에 있는 실수 벡터입니다.
그래서 텍스트를 복원하려면 이 벡터들을 다시 가장 가까운 단어로 **"반올림

3. 실험 결과
총 6가지 제어 과제에서 기존 방법들(FUDGE, PPLM 등)과 비교 실험.

결과 요약:
Semantic Content: 81.2% 성공률 (FUDGE: 69.9%, PPLM: 9.9%)
POS 제어: 90.0% 성공 (FUDGE: 27.0%)
Syntax Tree: 86.0% 성공 (FUDGE: 17.9%)
Syntax Span: 93.8% 성공 (FUDGE: 54.2%)
Length 제어: 99.9% 성공 (FUDGE: 46.9%)

복합 제어 (예: 내용 + 구문)에서도 기존 plug-and-play 또는 fine-tuning 방식보다 높은 성능 달성.
문장 중간 삽입 (infilling) 과제에서도 DELOREAN, COLD 등 기존 방식보다 BLEU, ROUGE, BERTScore 모두 우수.

4. 논문의 한계
추론 속도: AR-LM은 길이에 따라 O(n), 하지만 Diffusion-LM은 200~2000 step의 denoising이 필요해 추론 시간이 느림.
Perplexity 기준 성능은 autoregressive LM보다 떨어짐 (E2E: 2.28 vs 1.77, ROCStories: 3.88 vs 3.05).
학습 안정화에 다양한 트릭이 필요하며, 훈련 수렴 속도도 느림.
Latent rounding의 정확도 보장 어려움 → clamping 등의 보완 기법을 사용해야 함.

이 기술이 왜 작동하는지를 분석하기 위해,
모델 용량이 제한된 상황에서 score matching이 데이터 분포의 저확률(즉, 학습이 부족하고 가능성이 낮은) 영역을 과도하게 강조하는 경향이 있다는 점을 떠올려 보자.
정확히 어떤 위치에서 어떤 문제가 나타날지는 네트워크 아키텍처, 데이터셋, 학습 세부 사항 등에 따라 달라지며,
사전에 이를 구체적으로 식별하거나 특성화하기는 어렵다.

그러나 동일한 모델의 더 약한 버전은 비슷한 영역에서 유사한 오류를 더 강하게 일으킬 것이라고 기대할 수 있다.
Autoguidance는 강한 모델의 출력과 약한 모델의 출력 차이를 측정하고 이를 증폭시켜
강한 모델이 만든 오류를 식별하고 줄이는 것을 목표로 한다.

디퓨전 모델에서 말하는 섭동은 원래 모델(강한 모델)이 예측한 방향에서, 약한 모델과의 차이만큼 방향을 수정해주는 조정값을 의미

따라서, 두 모델이 서로 호환 가능한 열화(degradation)를 겪는 경우,
autoguidance는 효과적으로 작동할 수 있다.
실제로 어떤 D₁도 용량 부족 또는 학습 부족 등의 문제를 어느 정도는 겪고 있을 것이므로,
D₀는 이러한 측면을 의도적으로 더 악화시키는 방식으로 설계하는 것이 합리적이다.

실제 상황에서는 두 모델이 별도로 학습되거나 반복 횟수가 다르면,
단순한 정확도 차이 외에도 무작위 초기화, 학습 데이터 순서 섞임 등이 다를 수 있다.
가이드가 성공적으로 작동하려면, 품질 격차가 무작위 요인을 압도할 정도로 충분히 커야 한다.

실험 세팅
기본 모델:
EDM2-S 모델 (ImageNet-512로 학습, dropout 없음)

FID = 2.56

드롭아웃 손상:
D₁: 기본 모델에 사후(post-hoc) 방식으로 5% dropout 적용 → FID = 4.98
D₀: 동일하게 10% dropout 적용 → FID = 15.00

 autoguidance 적용 시,
w = 2.25일 때 최고 성능: FID = 2.55
→ 기본 모델 수준까지 회복됨

 노이즈 손상:
D₁: 입력 이미지에 10% 추가 노이즈 → FID = 3.96
→ 디노이저의 σ 조건도 이에 맞게 조정
D₀: 동일한 방식으로 20% 노이즈 추가 → FID = 9.73

autoguidance 적용 시,
w = 2.00일 때: FID = 2.56
→ 역시 기본 모델 수준 회복

불일치하는 손상 조합 (dropout vs input noise):
D₁에 dropout, D₀에 input noise 적용 (혹은 그 반대)
→ guidance는 성능 향상에 전혀 도움이 되지 않음
이 경우 w = 1 (guidance off)일 때가 가장 좋은 성능을 보임


이 실험은 우리의 주요 가설을 뒷받침하지만,
실제 생성 모델에 이런 합성 손상을 넣어 가이드 모델을 만드는 것이 유용하다고 주장하는 것은 아니다.
실제 디퓨전 모델은 이런 특정 손상을 겪지 않기 때문에,
그런 방식으로 가이드 모델을 만들면 데이터 매니폴드로의 일관된 수렴(truncation)을 이끌 수 없다.
더 현실적인 방식으로 약한 모델 D₀을 구성해야 함 (예: 학습 덜 된 버전, 작은 모델 등)


<데이터 매니폴드>
는 고차원 공간 속에서 실제 의미 있는 데이터들이 분포하는 저차원 구조
좋은 생성 모델은 그 매니폴드를 잘 따라야함
매니폴드 밖에 있는 결과는 이상한 이미지, 깨진 그림, 여섯 손가락 사람 같은 걸 만듬
그 표현 벡터들이 실제로 분포하는 구조적 공간.

예를 들어 모든 ‘고양이 이미지 표현’이 존재하는 저차원 곡면 같은 것.

비유로 쉽게 설명하면:
이미지 하나를 표현 학습하면 → 벡터 하나 얻음 → 매니폴드 위의 한 점
비슷한 이미지들을 다 표현하면 → 벡터들이 몰림 → 매니폴드가 형성됨
이 매니폴드는 “이런 종류의 데이터가 나올 수 있는 공간”을 뜻함.


CFG나 Autoguidance는 이 매니폴드로 잘 수렴하게 돕는 역할

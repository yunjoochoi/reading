1. 논문이 나오게 된 배경
최근의 AI 모델들은 다양한 데이터(modality)와 작업에 대해 점점 유사한 표현 공간(Representation)을 학습하고 있습니다. 텍스트 모델과 비전 모델, 서로 다른 아키텍처와 학습 목표를 가진 모델들조차도 유사한 유클리드 공간에 데이터를 매핑하며, 이는 표현의 수렴(Representational Convergence)으로 나타난다.

궁극적으로 모든 모델이 현실 세계의 통계적 구조(Z)를 학습함으로써, 플라톤적 표현(Platonic Representation)으로 수렴한다는 가설을 제안

왜 표현이 수렴하는가?

수렴은 어디까지 이어지는가?

그 끝에 존재하는 궁극의 표현은 무엇인가?

2. 표현 공간의 구조를 수학적으로 분석하고 여러 기존 모델 간의 유사도(Alignment)를 계산
표현 함수: f: X → ℝⁿ

커널 함수(Kernel): K(xi, xj) = ⟨f(xi), f(xj)⟩

정렬 지표(Alignment metric): 상호 최근접 이웃의 평균 교집합 크기 등 (CKA, SVCCA와 유사)

이런 정의들을 기반으로, 다양한 모델의 표현이 얼마나 유사한지를 커널 기반 유사도 지표로 정량적으로 측정하고 분석


3. 실험 결과
단일 모달리티 내 수렴:
  Vision 모델 78개를 분석한 결과, 다양한 아키텍처/목표를 가진 모델이라도 성능이 높을수록 서로 표현이 유사해지는 경향을 보임.
  VTAB 벤치마크 기준으로 성능이 높을수록 모델 표현 간 정렬도가 높음 

모달리티 간 수렴:
 LLM과 Vision 모델 간에도 표현 정렬 현상이 발견됨.
 Wikipedia caption dataset(WIT)을 사용해 paired 이미지-텍스트 표현 간 정렬도를 측정.
 성능 좋은 언어모델일수록 좋은 Vision 모델과 표현 정렬도가 높음

정렬도와 다운스트림 성능의 관계:
 Vision 모델(DINOv2)과 높은 정렬도를 보이는 LLM일수록 commonsense reasoning (HellaSwag), 수학 문제 풀이(GSM8K) 등의 성능이 높음

뇌와의 정렬:
 인간 시각 피질과 CNN의 early layer는 Gabor-like 필터를 공유.
 뇌와의 alignment 역시 커지고 있다는 증거들이 존재함.


4. 의의
통합 표현 이론의 제시:
다양한 모델들이 공유하는 통계적 구조가 있다는 가설을 처음으로 철학적·수학적으로 체계화.
이를 "플라톤적 표현 공간"이라는 개념으로 설명.

기존 연구의 통합:
self-supervised, supervised, cross-modal 모델들 간 표현 유사성에 대한 연구들을 하나의 수렴 프레임워크로 통합.

기술적 함의:
표현 정렬이 성능 향상과 관련 있다는 사실은 모델 선택, 앙상블, 파인튜닝 전략에도 실질적 영향을 줄 수 있음.


5. 논문의 한계
검증 불가능한 철학적 가설:
'플라톤적 이상 표현'이라는 개념은 아름답지만 실증적으로 완전히 증명하기 어렵다.
"실제 현실 Z"가 무엇인지도 불명확하며, 이것이 수렴의 종착지인지 여부는 철학적 추론에 가깝다.

표현 정렬의 인과성 불명확:
표현이 수렴해서 성능이 높은 것인지, 성능이 높기 때문에 수렴하는 것인지 인과 관계가 불분명.

한계적인 정렬 지표:
Alignment metric은 주로 벡터 간 내적 기반이므로, 복잡한 표현 공간 구조의 모든 측면을 포착하지는 못함.

모달리티 차이 간 정보 손실 문제:
예를 들어 이미지와 텍스트 간 표현 정렬이 된다고 해도, 시각적 세부정보나 시맨틱 손실 가능성 존재.

그냥 인터넷에서 모은 데이터셋이 많아질수록 곂치는 데이터로 학습해서 당연히 모델 표현도 수렴할수밖에 없다는 비판

하지만 실제로 실험해본 결과, 이 방식은 모달리티 간 격차(modality gap)라는 문제에 시달립니다 [67, 7, 58]. 즉, 의미적으로 유사한 항목들끼리 클러스터링되는 것이 아니라, 같은 모달리티끼리 뭉쳐서 클러스터링되는 경향이 나타납니다(이는 Figure 2 및 Figure 8에서 시각화됨). 그 결과, 검색 시 질의와 같은 모달리티의 지식만을 편향적으로 검색하게 되고, 다른 모달리티에 존재하는 중요한 정보는 무시되는 문제가 발생

이러한 문제를 해결하기 위해 UniversalRAG는 모든 모달리티를 하나의 공유 임베딩 공간으로 억지로 통합하는 방식을 버리고, 대신 모달리티 인식 라우팅 전략(modality-aware routing strategy)**을 도입

이 전략의 핵심 장점은 다음과 같습니다:

모달리티 간 비교(cross-modal comparison) 자체를 회피함으로써 모달리티 격차 문제를 근본적으로 회피할 수 있으며,

기존의 모달리티 전용 검색기(modality-specific retriever)를 수정하지 않고, 단지 라우팅 로직만 확장함으로써 새로운 모달리티를 쉽게 통합할 수 있다는 것입니다.


모달리티 외에도 중요한 관점 중 하나는 데이터의 세분화 수준(granularity)입니다. 이는 코퍼스 내에서 각 항목의 크기나 단위를 의미하며, 검색 정확도와 생성 품질 모두에 영향을 미칩니다 [11, 70]. 동일한 모달리티 내에서도 질의 유형에 따라 적절한 granularity 수준이 다르기 때문입니다.

예를 들어:

너무 세분화된 항목은 문맥을 분산시켜 정보가 단절될 수 있고,

너무 큰 단위는 관련 없는 정보가 함께 묶여 노이즈가 될 수 있습니다.

예시:
복잡한 분석형 질문은 전체 문서나 장문의 영상처럼 긴 컨텍스트가 필요하지만,

단순한 사실 질의는 짧은 문단이나 짧은 영상 클립 하나만으로 충분

UniversalRAG는 각 모달리티를 여러 세분화 수준(granularity levels)으로 나누어 별도 코퍼스로 구성합니다:

텍스트는 문서 단위 외에도 문단 단위로 분할하여 별도의 코퍼스에 저장

비디오는 전체 영상 외에도 짧은 클립으로 나누어 저장

이미지는 단일 단위로 의미가 완결되므로 별도 분할 없이 그대로 유지

또한, 외부 지식이 필요 없는 **단순 질의에 대해서는 검색 없이 직접 생성(no-retrieval option)**하는 경량 경로도 함께 제공합니다.

이처럼 **모달리티 + 세분화 수준(granularity)**을 모두 고려한 다양한 유형의 코퍼스를 구성하고,
질의가 요구하는 정보의 유형과 복잡성에 따라 동적으로 라우팅함으로써,
UniversalRAG는 현실 세계 사용자들의 다양한 정보 요구를 효과적으로 지원할 수 있습니다.

2.3 UniversalRAG의 Router 구현 전략
UniversalRAG의 핵심 구성 요소인 Router는 질의에 따라 가장 적절한 **모달리티(modality)**와 **세분화 수준(granularity)**을 판단하는 역할을 수행합니다. 이를 구현하기 위해 논문에서는 두 가지 전략을 제안합니다.

 1. Training-free Router (학습 없이 동작하는 라우터)
이 전략은 GPT-4o, Gemini와 같은 최신 LLM의 강력한 범용 지식과 추론 능력을 활용하여, 추가 학습 없이 직접 프롬프트 기반으로 Router 역할을 수행

2. Training-based Router (학습 기반 라우터)
더욱 정밀한 라우팅 정확도를 달성하기 위해, 라우터 자체를 지도 학습 방식으로 훈련시키는 전략도 함께 제안됩니다.

하지만 이 방식에서 가장 큰 문제는 모달리티/세분화에 대한 정답 라벨이 존재하지 않는다는 점




모달리티간 격차라는게 의미를 모르겠음 당연히 모달리티간엔 격차ㅇ가 있는거 어닌가?
그리고 pca같은 차원축소쓰면 방향 정렬된거 당연히 무시되는게 아닌가? 고차원으로 다시 띄우면 유의미한 클러스터나 방향성이 생길 수 있는데

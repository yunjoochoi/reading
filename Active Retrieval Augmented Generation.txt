<Active Retrieval Augmented Generation>
일반적인 래그 방법은 유저 인풋을 이용해 단 한번만 관련 컨텍스트를 찾아오고 이를 활용해 답변을 생성하는 식으로 사용된다.
이런 싱글 타임 리트라이브는 그냥 파라메트링 llm보다는 뛰어나지만, (특히 한번의 리트라이브로도 충분한 짧은 지식 OA에서)
최근 llm은 롱폼 아웃풋을 생성하는 데도 파워풀함 다만 이런 롱폼 생성은 유저 인풋에서 명확히 리트라이브가 한번으로 불가능함. 여러 단계에 걸쳐 리트라이브해야할 수 있다. 
사람이 에세이 쓸 때 배경지식 모으는 것을 생각하면 간단함
생성 도중 인포 리트라이브가 피요할 수 있다. 생성 중 언제, 무엇을 리트라이브해야하는지 판단가능한 llm, 특히 필요하지 않은 인포까지 리트라이브하려는 시도를 하지 않아야 한다. 
=>낮은 확률/신뢰도는 종종 지식 부족을 나타낸다는 관찰 결과를 고려하여(Kadavath et al., 2022), LM이 낮은 확률의 토큰을 생성할 때만 검색하는 능동적 검색 전략을 채택
(방법)
다음에 무슨 지식이 필요할지 예측 위해 텀포럴하게 다음 문장(q)을 생성하고, 그 문장을 관련 문서 쿼리하는 용으로 사용한다. (만약 그 문장이 낮은 확률의 토큰을 가지고 있을 시에만, 구현 시 logprobs으로 확인가능) 이후 가져온 인포로 다음 문장을 재생성한다.
**Inference Time: 주어진 입력에 대해 모델이 출력을 생성하는 데 걸리는 시간

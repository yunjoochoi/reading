Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors

INTRO
멀티모달 모델들은 텍스트 입력만으로 이미지를 생성하지만, 이 방식은 구조적 제어가 어렵고 예측 불가능한 결과를 초래
텍스트 입력과 함께 장면(scene) 스케치를 추가로 제공하여 이미지 생성의 제어성을 높이고, 특정 영역(예: 얼굴, 주요 객체)의 품질을 향상시키는 방법을 제안

1. 제어성: 텍스트는 이미지를 완전히 설명 못한다
(ii) 인간 인지(Human perception): 이미지는 인간의 인지와 주의에 맞춰 생성되도록 하지만, 생성 과정에는 관련된 사전 지식이 포함되지 않아, 생성과 인간의 주의 사이에는 상관관계가 거의 없다
(iii) 품질 및 해상도(Quality and resolution): 연속적인 방법들 사이에서 품질이 점진적으로 향상되었음에도 불구하고, 이전의 최첨단(state-of-the-art) 방법들은 여전히 256 × 256 픽셀의 출력 이미지 해상도로 제한

연구에서는 이러한 핵심적인 격차들을 성공적으로 해결하는 동시에 텍스트-이미지 생성 작업에서 최첨단 결과를 달성하는 새로운 방법을 소개. 텍스트를 보완하는 새로운 유형의 제어를 제공하여, 구조적 일관성과 품질을 향상시키면서 새로운 세대의 생성 능력을 가능하게 합니다. 더욱이, 우리는 인간의 선호도와 상관관계가 있는 명시적인 손실(explicit losses)을 제안하여 이미지 품질을 크게 향상시키고, 일반적인 해상도 장벽을 깨뜨려 512 × 512 픽셀 해상도의 결과를 생성.

we introduce implicit conditioning over optionally controlled scene tokens, derived from segmentation maps
우리의 컨트리뷰션은 장면 형태의 컨트롤하는 요소들을 추가, 토큰화향상, 트랜스포머에 분류기 없이도 가이드 가능하게 함

3. Method
텍스트 입력과 선택적인 장면 레이아웃(분할 맵)으로부터 이미지를 생성
improving the general and perceived quality with a better representation of the token space. =토큰화 프로세스를 수정해서 얼굴 및 두드러진 객체(salient objects)와 같이 인간의 관점에서 중요성이 증가하는 측면에 대한 인식을 강조

3.1. Scene representation and tokenization
모델이 이미지를 생성할 때 "장면(scene)"을 어떻게 이해하고 활용하는지: 세 가지 종류의 의미론적 분할
파노라마 분할 (Panoptic segmentation): 이미지 전체의 객체와 배경을 포괄적으로 분할합니다. (참고 문헌 [63])
인간 분할 (Human segmentation): 사람 영역을 정교하게 분할합니다. (참고 문헌 [35])
얼굴 분할 (Face segmentation): 얼굴 부분을 세밀하게 분할합니다. (참고 문헌 [5]의 방법을 사용해 추출)

의미론적 레이아웃은 왜 사용하는가? 이 레이아웃은 이미지 전체에 대한 추가적인 맥락(global context)을 암시적인 형태로 제공
암시적인 이유는 네트워크는 필요하다면 이 장면 정보를 완전히 무시하고 오직 텍스트 설명에만 의존해서 이미지를 생성할 수 있다. 

3.2. 토큰 공간에서 인간의 강조점 반영 

3.3. 장면-트랜스포머: 장면 기반 텍스트-이미지 생성 



실험 (Experiments)
FID 점수와 인간 선호도 지표를 사용하여 이전 연구들과 비교

결론 (Conclusion)
 상호작용적인 경험으로의 전환을 강조. 얼굴이나 주요 객체와 같이 인간의 인지에서 중요한 핵심 이미지 측면을 개선하는 데 초점을 맞춤으로써 인간 평가와 객관적 지표 모두에서 더 높은 선호도를 이끌어냈음을 강조

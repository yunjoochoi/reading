Vector Quantized Diffusion Model for Text-to-Image Synthesis

1. 논문이 나오게 된 배경
기존의 텍스트-이미지 생성 모델들은 몇 가지 주요한 한계점
자기회귀 모델의 한계
 단방향 편향: ar모델은 토큰을 순서대로 예측한다. 이미지 문맥 정보 반영의 여려움
 오차 누적: 추론 단계에서 ar모델은 이전 토큰 기반으로 다음 토큰도 예측하므로 오차 전파된다
 느린 생성 속도: 토큰을 순차적으로 생성해야 하므로 이미지 해상도가 커질수록 생성 시간이 선형적으로 증가하여 고해상도 이미지 생성에 많은 시간이 소요

GAN기반 모델의 한계는 단일 도메인 셋에서는 고품질이지만 여러 객체가 포함된 복잡한 장면 처리에는 어려움이 있다. 

=>VQ-Diffusion 모델 제안

2. 아키텍처 설명
1. VQ-VAE로 이미지를 저차원의 이산적인 잠재 공간 표현으로 압축
=VQ-VAE는 이미지를 저차원의 이산적인(discrete) 잠재 공간 표현으로 압축하는 역할, 이미지는 이산적인 토큰 시퀀스가 된다

2. Vector Quantized Diffusion
 VQ-VAE로 얻어진 이산적인 잠재 공간에서 작동하는 DDPM
순방향: 원본 이미지 토큰 x 에 점진적으로 노이즈를 추가하는 고정된 마르코프 연쇄(Markov chain)를 통해 여러 타임스텝 T에 걸쳐 순수한 노이즈 상태인 xT로 만든다.
역방향: 순수노이즈 xT상태에서 시작해서 텍스트 조건 y와 현재 노이즈 상태인 xT를 입력으로 받아 점진적인 노이즈 제거해서 원본이미지 x0만든다. 디코더는 트랜스포머 기반의 디퓨전 이미지 디코더이다. 
이 디코더는 텍스트 인코더로부터 텍스트 정보를 받고, 이미지 토큰의 전체 문맥 정보를 활용하여 양방향 어텐션을 수행=단방향 편향 해결
핵심 전략: 마스크-앤-리플레이스 확산 (Mask-and-replace diffusion strategy: 학습 시 티쳐포싱하지 않고 일부 토큰을 마스크 토큰으로 치환한다 뉴럴넷은 이렇게 손상된 토큰들을 원해대로 예측한다. 
추론 시에는 매 스텝마다 모든 토큰의 확률 분포를 새로 계산하고, 이 분포에 따라 모든 토큰을 다시 샘플링합니다. 이를 통해 이전 스텝에서 발생했을 수 있는 오류를 현재 스텝에서 수정할 기회를 갖게 되어 오류 누적을 방지
균일 노이즈(uniform noise): 코드북에 있는 K개의 가능한 모든 실제 토큰 중 하나로 무작위적이고 균일한 확률로 대체되는것, 
이미지의 일부에 예측 불가능한 무작위적인 변화를 주어, 네트워크가 단순히 가려진 부분([MASK])만 맞추는 것이 아니라 주변 문맥을 더 깊이 이해하고 잘못된 토큰도 수정할 수 있도록 강제하는 역할.


3. 실험
Truncation 샘플링: 추론 시 확률이 낮은 토큰을 제외하고 상위 r개의 토큰만 고려하는 Truncation 샘플링 전략이 이산 확산 모델에서 중요하며, 특정 Truncation 비율(예: 0.86)에서 최적의 성능

4. 정리
VQ-Diffusion의 가장 큰 장점은 각 discrete 토큰의 확률을 추정할 수 있다 - 고품질 이미지를 상대적으로 적은 inference step으로 생성가능


**교사 강요는 (n-1) 스텝의 예측 값을 n 스텝의 입력값으로 사용하는 것이 아니라 (n-1) 스텝의 실제값을 n 스텝의 입력값으로 넣어주는 방식이다. 
이유= (n-1) 스텝의 예측값이 실제값과 다를 수 있기 때문이다. 예측은 예측일 뿐 실제와 다를 수 있다. 따라서 정확한 데이터로 훈련하기 위해 예측값을 다음 스텝으로 넘기는 것이 아니라 실제값을 매번 입력값으로 사용하는 것이다. 이런 방식을 교사 강요라고한다
헷갈릴까봐 다시 설명하자면 디코더의 훈련 단계에서는 필요한 데이터가 Context 벡터와 <sos>, je, suis, étudiant이다. 
하지만 테스트 단계에서는 Context 벡터와 <sos>만 필요하다. 훈련 단계에서는 교사 강요를 하기 위해 <sos>뿐만 아니라 je, suis, étudiant 모두가 필요한 것이다. 하지만 테스트 단계에서는 Context 벡터와 <sos>만으로 첫 단어를 예측하고, 그 단어를 다음 스텝의 입력으로 넣는다.

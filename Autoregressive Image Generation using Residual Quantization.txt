1. 논문이 나오게 된 배경
기존의 고해상도 이미지 생성을 위한 Autoregressive (AR) 모델은 Vector Quantization (VQ) 기반 VQ-VAE를 활용해 이미지를 이산 코드 시퀀스로 표현했지만,
 (1) 긴 시퀀스 길이로 인해 AR 모델의 계산 비용이 크고,
 (2) 고품질 이미지 재생성을 위해서는 매우 큰 코드북이 필요해 학습이 불안정해짐 (codebook collapse 문제).

=> 따라서 이 논문은 고해상도 이미지를 짧은 시퀀스로 표현하면서도 고품질 재구성을 가능하게 하는 새로운 이산 표현 방식을 제안

2. 아키텍쳐 
논문은 2단계 프레임워크로 구성

● Stage 1: RQ-VAE (Residual-Quantized VAE)

기존 VQ 대신 Residual Quantization (RQ) 을 적용하여 고정된 코드북 크기 안에서 여러 개의 잔차 코드를 통해 벡터를 점진적으로 근사.

결과적으로 이미지를 stacked discrete codes (예: 8x8 spatial resolution, D=4 depth) 로 표현하여 짧은 시퀀스 확보.

공유된 단일 코드북을 모든 깊이에서 사용하여 코드 활용률을 극대화

● Stage 2: RQ-Transformer
RQ-VAE의 코드 시퀀스를 기반으로 다음 위치의 D개의 코드를 예측하는 Transformer.

구조는 Spatial Transformer + Depth Transformer 로 구성:

Spatial Transformer: 시퀀스 내 공간 위치 t 간의 관계 학습

Depth Transformer: 각 위치에서 깊이 d에 따라 coarse-to-fine 방식으로 코드 예측

● 추가 학습 기법

Soft Labeling: 코드 간 유사도를 고려한 부드러운 정답 분포 사용

Stochastic Sampling: 코드 선택을 확률적으로 하여 학습과 추론 간의 분포 불일치(Exposure Bias) 감소


3. 실험 결과

언컨디셔널- 기존 AR 모델(VQ-GAN, DCT 등) 대비 더 낮은 FID 달성
컨디셔널- VQ-GAN, ImageBART보다 높은 FID, IS, CLIP-Score 달성
샘플링 속도: VQ-GAN 대비 최대 7.3배 빠른 이미지 생성 속도

4. 의의
 Residual-Quantized VAE
RQ 기반 VAE를 통한 짧은 이산 시퀀스 표현: 기존 VQ의 한계를 극복하면서도 정보 보존

AR 모델의 계산 효율성 향상: Transformer의 길이를 줄이면서도 고품질 이미지 생성 가능

다양한 조건 하에서 SOTA 수준 성능 달성: class-conditioned, text-conditioned 이미지 생성까지 확장 가능

코드북 효율성 증가: 코드북 공유 구조와 residual 방식으로 코드 재사용 및 활용도 증대

5. 논문한계
작은 데이터셋에서는 StyleGAN2보다 성능이 낮음 (예: FFHQ) → AR 모델의 과적합 문제

거대한 모델과 데이터셋 기반의 zero-shot text-to-image 확장 연구 부족 → 향후 대규모 트랜스포머 적용 가능성

AR 모델은 단방향적 생성만 가능 → 이미지 인페인팅/아웃페인팅 같은 양방향 맥락 활용 어려움(가능은 한데 왼쪽 아래  부분은 고려가 안되겠지, 시각적 일관성 디퓨전에 비해 저하됨)


INTRO
We postulate that reducing the sequence length of codes is important for AR modeling of images
코드 길이 자체를 줄이는 것의 필요성
시퀀스 길이를 줄이기 위해 해상도를 낮추면 정보가 손실되어 재구성 이미지 품질이 떨어짐.

이를 보완하려면 더 큰 코드북이 필요하지만, 이는 학습 불안정(codebook collapse) 등의 문제를 유발함.
RQuses a fixed size of codebook to recursively quantize the feature map in a coarse-to-fine manner.
-> D iterations =the feature map is represented as a stacked map of D discrete codes.
RQ는 코드북 크기의 D(4)제곱만큼 많은 벡터를 구성할 수 있기 때문에, 큰 코드북 없이도 인코딩된 이미지 정보 보존 가능 while conserving the information of the encoded image without a huge codebook

RQ-VAE가 추출한 코드들을 예측하기 위해 RQ-Transformer를 제안
RQ-Transformer의 입력으로는, RQ-VAE의 양자화된(feature map) 특성 맵을 이산 코드 시퀀스로 변환한 것이 사용


stacked code map: H×W×D 1차 시퀀스로 바꾸면:  총 T개의 위치, 각 위치마다 D개의 코드
이미지 복원(decode)은 D개마다 끊어서 각 위치의 벡터를 재구성한 뒤 → 디코더(G)에 넣어 복원
 
<Exposure Bias> 문제란?
학습 중에는 ground-truth 코드로 예측하게 하지만,
실제 추론 시에는 이전 예측 결과에 의존
→ 이 불일치 때문에 오차가 점점 누적되는 현상 발생 (특히 AR 구조에서 심각)
기법	                                       역할	       적용 시점	         목적
Soft Labeling	정답 라벨을 soft 분포로 제공	학습 시	임베딩 간 유사도 반영, 학습 안정화
Stochastic Sampling	코드를 확률적으로 선택	학습 시	예측 시의 불확실성 반영, exposure bias 완화

VQ-VAE 
Neural Discrete Representation Learning, Vector Quantised Variational AutoEncoder (VQ-VAE)

지도 학습 없이 유용한 표현을 학습하는 것은 여전히 머신러닝에서 핵심적인 도전 과제입니다.
이 논문에서는 이산(discrete) 표현을 학습하는 간단하지만 강력한 생성 모델을 제안.
기존 VAE와 두 가지 중요한 차이점
1. 인코더 네트워크의 출력이 연속적(continuous) 값이 아니라 이산적(discrete) 코드라는 점,(기존 VAE는 연속적인 잠재 공간 사용)
2. 사전 분포(prior)가 고정(static) 되어 있는 것이 아니라 학습된다는 점. (기존 VAE에서는 잠재 공간의 분포가 표준 정규 분포(N(0,I))와 같아지도록 KL 발산 손실을 통해 강제)

이산적인 잠재 표현을 학습하기 위해, 벡터 양자화(vector quantisation, VQ) 개념을 도입
신호 처리 분야에서 유래한 기술로, 연속적인 입력 벡터를 가장 유사한 이산적인 "코드북(codebook)" 내의 벡터로 매핑하는 과정입니다. 코드북은 대표적인 벡터들의 집합입니다. VQ-VAE에서는 인코더가 출력한 연속적인 벡터를 이 코드북에서 가장 가까운 벡터로 대체하여 이산적인 표현을 얻습니다. 코드북 자체도 학습 과정에서 업데이트.

VQ 방법을 사용하면 VAE 프레임워크에서 일반적으로 관찰되는 "사후 분포 붕괴(posterior collapse)" 문제 – 강력한 자기회귀 디코더와 결합될 때 잠재 변수가 무시되는 현상 – 를 피할 수 있습니다.
사후 분포 붕괴 (Posterior Collapse): VAE에서 매우 강력한 디코더 (예: PixelCNN, WaveNet과 같은 자기회귀 모델)를 사용하면, 디코더가 인코더로부터 받은 잠재 변수 z를 거의 사용하지 않고도 입력을 잘 재구성해버리는 문제가 발생할 수 있습니다. 이 경우, 인코더가 출력하는 잠재 변수의 분포(사후 분포, q(z∣x))는 사전 분포(p(z))와 거의 동일해져 버리고, 잠재 변수 z는 데이터 x에 대한 유용한 정보를 거의 담지 못하게 됩니다.

VQ-VAE가 이 문제를 해결하는 방식: VQ-VAE는 잠재 공간을 이산적으로 만듭니다. 디코더는 연속적인 잠재 변수 대신 코드북의 특정 엔트리를 입력으로 받습니다. 이 이산적인 정보는 디코더가 무시하기 더 어렵습니다. 또한, 사전 분포를 학습하기 때문에, 잠재 공간의 정보 용량(information capacity)이 고정되지 않고 데이터의 복잡도에 맞춰 조절될 수 있어, 잠재 변수가 유의미한 정보를 담도록 강제하는 효과가 있습니다.


1 Introduction
기존의 많은 표현 학습 연구는 VAE처럼 연속적인(continuous) 실수 값으로 특징을 표현하는 데 중점을 두었습니다.
그러나 VQ-VAE는 이산적인(discrete) 표현, 즉 한정된 개수의 값 중 하나로 특징을 표현하는 데 집중합니다.
이산적 표현이 더 자연스러운 이유:
언어 (Language): 단어나 문자 같은 이산적인 요소로 구성됩니다.
음성 (Speech): 음소나 단어 같은 이산적인 기호의 연속으로 표현될 수 있습니다.
이미지 (Images): "고양이가 소파 위에 앉아 있다"처럼 언어(이산적)로 간결하게 묘사될 수 있습니다. 즉, 이미지의 핵심 내용은 이산적인 개념들로 요약될 수 있습니다.
추론, 계획, 예측 (Reasoning, Planning, Prediction): "비가 온다 (조건) → 우산을 쓴다 (행동)"와 같이 이산적인 상태나 개념을 기반으로 하는 경우가 많습니다.


이산적 잠재 변수의 어려움과 해결책:
딥러닝 모델에서 이산적인 잠재 변수를 다루는 것은 연속 변수보다 일반적으로 더 어렵습니다 (예: 미분이 직접적으로 어렵기 때문에 역전파가 복잡해짐).
하지만, 강력한 자기회귀 모델(powerful autoregressive models) (예: PixelCNN, Transformer)들이 개발되면서, 이러한 이산 변수들의 분포를 효과적으로 모델링할 수 있는 방법이 생겼습니다. VQ-VAE는 이산적인 잠재 코드들의 사전 분포(prior)를 학습하기 위해 이러한 자기회귀 모델을 활용합니다.


 핵심은 주어진 데이터 x에 대한 이산 잠재 변수 z의 사후 분포 q(z∣x)를 모델링하는 **새로운 방식(novel parameterisation)**을 사용했다는 점입니다. VAE는 인코더가 이 사후 분포를 근사하는데, VQ-VAE는 이를 이산적인 코드북을 통해 효과적으로 수행합니다.
벡터 양자화(VQ) 기반: 이전 문단에서 설명했듯이, 인코더의 출력을 코드북 내의 가장 가까운 벡터로 매핑합니다.

VQ-VAE는 잠재 공간을 효과적으로 사용할 수 있기 때문에, 종종 지역적인(local) 노이즈나 감지하기 어려운 세부 사항에 집중하거나 용량(capacity)을 소비하는 대신, 일반적으로 데이터 공간에서 많은 차원에 걸쳐 있는 중요한 특징들(예: 이미지에서 여러 픽셀에 걸쳐 있는 객체, 음성에서의 음소, 텍스트 조각에서의 메시지 등)을 성공적으로 모델링
---------------------------------------------------
Method
1. 이미지에서 특징 추출하여 피쳐맵 만들고 이 피쳐맵에서 각 픽셀마다 코드북의 임베딩 벡터와 비교해서 가장 유사한 코드북의 벡터 인덱스를 그 (피쳐맵)위치의 이산적인 표현으로 사용한다.

2. 근데, 그러면 결국엔 코드북의 벡터로 통일하는 과정에서 손실이 생길거고 손실 정도는 코드북의 임베딩 벡터 수와 관련이 있다. 

3. 결국 이산적인 표현은 약간 트릭같은 건데 - 결국 벡터정보를 이산 코드로 매핑한 거기도 하고 - 그럼에도 불구하고 이점이 있다
"Posterior Collapse" 문제 해결: VAE에서 강력한 디코더를 사용하면 잠재 변수가 무시되는 현상(posterior collapse)이 발생하기 쉽습니다. VQ-VAE는 인코더의 출력을 코드북의 이산적인 코드로 강제로 매핑함으로써, 디코더가 이 잠재 코드를 무시하기 어렵게 만듭니다. 정보가 이 "이산적인 병목"을 반드시 통과해야 하므로 잠재 공간이 유의미한 정보를 학습하도록 강제


코드북의 각 개별 벡터(임베딩)가 일반적으로 하나의 완전한 물체(예: '개' 한 마리 전체, '자동차' 한 대 전체)를 직접적으로 대표하지는 않고, 코드북의 벡터들은 다음과 같은 더 작은 단위나 특징을 나타내는 경향
시각적 기본 단위 (Visual Primitives) 또는 빌딩 블록 (Building Blocks): 선의 특정 방향, 곡선, 모서리, 특정 질감 조각, 색상 패턴 등 이미지나 물체를 구성하는 더 기본적인 시각적 요소
부분적인 특징 (Partial Features): 물체의 일부분 (예: 개의 귀 모양, 자동차 바퀴의 일부, 특정 질감의 표면)을 나타낼 수 있다
압축된 특징 조각 (Compressed Feature Chunks): 인코더가 추출한 국소적인 특징 벡터를 대표하는 값
12번 코드는 '개의 털 질감의 일부분', 48번 코드는 '개의 눈 주변의 형태 일부', 5번 코드는 '배경의 특정 패턴' 등을 나타낼 수 있으며, 이러한 코드들이 특정 공간적 패턴으로 배열될 때 비로소 '개'라는 전체적인 물체 또는 장면의 일부가 인식될 수 있는 것([[12, 48, 5], [72, 3, 29], ...])
ex.모자이크 그림

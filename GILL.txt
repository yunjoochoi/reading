Autoregressive LMs 및 LLMs는 텍스트만으로 사전학습했음에도 불구하고,
이미지, 로봇, 강화학습 등 다양한 분야에 잘 적응할 수 있음.

이런 방식은 보통 모델 파라미터 대부분을 고정(frozen) 시켜두고,
입력만 추가하는 방식으로 적응

Our findings show that it is possible to efficiently map the output embedding space
of a frozen text-only LLM to that of a frozen generation model(여기서는 스테이블 디퓨전), 두모델이 완전히 다른 텍스트 인코더를 사용하고 있음에도 가능.

이미지-캡션 쌍으로 아무 적은 파라미터를 파인튜닝해서 달성했다, 또 트레이닝 시점에 이미지 제너레이터를 가동할 필요 없다


 GILLMapper module은 특별히 학습된 텍스트 토큰들에 조건(conditioning)된 경량 Transformer 모델
텍스트-투-이미지 생성 모델의 텍스트 인코더 출력과의 L2 거리를 최소화하도록 학습

추론 단계에서 생성된 이미지를 출력할지, 검색된 이미지를 출력할지를 결정하기 위해, 우리는 언어 모델의 히든 표현을 조건으로 삼는 결정 모델도 함께 학습시켰다.
이 구조 덕분에, 출력 시퀀스 내에서 이미지 생성과 이미지 검색을 모두 수행할 수 있게 된다


우리의 실험 결과는 GILL이 Stable Diffusion보다 긴 형태의 텍스트―예를 들어 대화나 담화와 같은 복잡한 문장 구조―를 처리하는 데 더 효과적
대화 기반 이미지 생성 실험에서는, GILL이 LLM이 아닌 기존 생성 모델들보다 우수한 성능을 보이며, 멀티모달 문맥 정보를 활용함으로써 원본 생성 모델보다도 텍스트에 더 잘 부합하는 이미지를 생성할 수 있음을 입증
GILL은 기존 텍스트-투-이미지 모델과 달리, 텍스트만이 아니라 이미지와 텍스트가 섞여 있는 입력 시퀀스도 자유롭게 처리
GILL은 검색된 이미지, 새롭게 생성한 이미지, 텍스트를 출력 시퀀스 내에서 혼합하여 다중모달 대화를 자연스럽게 생성할 수 있는 최초의 모델
The LLM hidden states of the [IMG] tokens are used for image retrieval and generation

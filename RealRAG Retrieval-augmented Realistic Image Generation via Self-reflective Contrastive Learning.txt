Retrieval-Augmented Diffusion Models: 리트리벌 해서 이미지 임베딩 후 크로스 어텐션에 넣어줌(이미지 투 이미지 참조 형식)
RealRAG: Retrieval-augmented Realistic Image Generation via Self-reflective Contrastive Learning
텍스트-투-이미지 생성 모델들(예: Stable Diffusion V3와 Flux)은 주목할 만한 발전을 이뤘습니다. 그러나 이러한 모델들은 폐쇄된 데이터셋으로 학습된 고정된 파라미터, 즉 제한된 지식에 강하게 의존한다는 단점
예를 들어 Tesla Cybertruck처럼 정교하거나 처음 보는 실제 세계의 객체를 다룰 때 환각(hallucination) 또는 왜곡(distortion) 현상이 심각
또한, 이 실제 객체 기반 프레임워크는 정교한 시각적 지식(fine-grained visual knowledge)을 생성 모델에 통합함으로써, 왜곡 문제를 해결하고 정교한 객체 생성의 사실성(realism)을 개선합니다.
우리의 RealRAG는 모듈식 설계로 되어 있어 최신 텍스트-투-이미지 생성 모델 전반에 적용 가능하며, 실제로 모든 모델에서 뛰어난 성능 향상을 보여주었습니다. 예를 들어, Stanford Car 벤치마크에서 오토레그레시브 모델과 함께 사용했을 때 FID 점수가 16.18% 향상되는 결과를 


하지만 텍스트-투-이미지 생성에서는 이러한 RAG 기법이 여전히 도전적인 과제로 남아 있습니다. 주로 **유사도 기반 검색(similarity matching)**에 의존하기 때문입니다. 구체적으로, Fig. 1 (b)와 (c)에 나타난 바와 같이, 텍스트 프롬프트와 **유사도가 가장 높은 이미지(후보 이미지 1)**는 이미지 생성 품질을 개선하지 못하는 반면, **유사도는 낮지만 부족한 지식을 보완해주는 이미지(후보 이미지 2)**는 오히려 생성 성능을 향상
이러한 문제를 해결하기 위해, 본 연구에서는 **자기반영 대조 학습(self-reflective contrastive learning)**을 통해 학습된 **반영적 검색기(reflective retriever)**를 제안합니다. 이 검색기는 가장 유사한 이미지 대신, 생성 모델이 부족한 지식을 보완해줄 이미지를 검색하는 데 초점
** 학습셋에 없는 처음보는 데이터에 대해 retrival 잘하도록 구성


자기반영 대조 학습(self-reflective contrastive learning)**을 통해 **반영적 검색기(reflective retriever)**를 학습시킵니다. 이때, 텍스트 프롬프트는 정답(positive)으로, 앞서 선택한 반영적 부정 샘플은 부정(negative)으로 사용합니다. 이와 같은 방식으로 학습된 검색기는 프롬프트와 관련성이 높을 뿐만 아니라, 생성 모델이 알지 못하는 정보를 포함한 이미지들까지도 검색할 수 있게 됩니다

자기반영 대조 학습을 통해 훈련된 반영적 검색기를 기반으로 텍스트-투-이미지 생성 모델의 사실성(realism)을 향상시키고 환각을 줄이는 것

RealRAG는 모든 유형의 텍스트-투-이미지 생성 모델에 통합 가능한 최초의 통합 RAG 프레임워크
보지 못한 신규 객체에 대한 생성 능력을 평가하기 위해, 우리는 최근 뉴스 웹페이지에서 신규 객체 이미지를 수집하고 이를 기반으로 **사람 평가(human evaluation)**를 수행

주어진 텍스트 프롬프트를 기반으로 특정 텍스트-투-이미지 생성 모델을 사용하여 이미지를 생성
이렇게 생성된 이미지들을 바탕으로, 이미지 데이터베이스에서 코사인 유사도(cosine similarity)가 가장 높은 이미지들을 선택하여 ‘반영적 부정 샘플(reflective negatives)’로 사용(이러한 샘플들은 생성된 이미지와 시각적으로 유사하며, 이는 생성 모델의 시각적 기억을 반영)
텍스트 프롬프트를 정답(positive)으로, 앞서 선택된 반영적 부정 샘플을 부정(negative)으로 활용하여 ‘자기반영 대조 학습(self-reflective contrastive learning)’ 방식으로 반영적 검색기(reflective retriever)를 학습

텍스트 프롬프트에 가장 잘 맞는 이미지가 반드시 생성 모델에 유용한 참조는 아닐 수 있다는 한계

3. Methodology
the goal is to ensure that I visually manifests the semantics conveyed by T.
이 과제는 조건부 확률분포를 학습하는 문제로 모델링
3.1. 자기반영 대조 학습 (Self-reflective Contrastive Learning)
생성기에 유용한 이미지를 검색하기 위해 자기반영 대조 학습(self-reflective contrastive learning)을 제안
=>생성기의 표현 공간(generation space)에서는 멀어지면서도, 텍스트 프롬프트의 표현에는 가까운 이미지를 검색하는 검색기를 학습하는 것
먼저 주어진 텍스트 프롬프트로부터 이미지를 생성한 다음, 해당 생성된 이미지를 쿼리(query)로 사용하여 실제 객체 기반 데이터베이스(real-object-based database)에서 가장 관련 있는 이미지를 검색합니다.
이렇게 선택된 관련 이미지들은 **반영적 부정 샘플(reflective negatives)**로 사용
선택된 반영적 부정 샘플은 높은 유사도를 가지므로,
생성기가 이미 알고 있는 지식을 포함하고 있으며,
생성기가 알지 못하는 현실 세계 기반 이미지들을 검색기(retriever)가 더 잘 포착할 수 있도록 도와준다.

텍스트 프롬프트로 이미지 생성한다.
실제 객체 기반 이미지 데이터베이스에서 생성한 이미지와 가장 유사한 이미지를 부정 샘플로 선택(반영적 부정 샘플 1개)
  =>생성기의 이미지 자체는 정확하지 않을 수 있지만, 그 "시도"는 텍스트 의미를 어느 정도 반영
	텍스트 프롬프트: "a futuristic truck" 생성기는 그 의미대로 그리려고 하지만, Cybertruck을 모를 수도 있음-어색한 이미지
	이 이미지와 유사한 실제 객체 이미지를 찾으면 진짜 Cybertruck 이미지 발견
	생성기의 시도 + 유사도 검색 → “텍스트 의미에 부합하는 현실 객체”에 가까운 실제 이미지가 선택됨
	

배치 사이즈 내에서 텍스트 프롬프트와 같은 배치 안에 있는 다른 (정답이 아닌) 이미지들 사이의 유사도를 계산하고(clip_) reflective negative 이미지와 텍스트 프롬프트 간의 코사인 유사도 기반 스코어를 분모에 추가

요약하면 clip 로스에서 Reflective Negative 항 D neg ref 이 분모에 추가됨. 생성기가 만든 이미지와 가장 유사한 실제 DB에서 선택된 이미지와(생성기가 만든 이미지와 가장 유사한 실제 이미지), 텍스트 프롬프트 간의 유사도를 낮추기 위해서이다. 즉, 그냥 비슷한 이미지를 찾아오게 하지 않고 유사한 이미지 중에 생성기가 가지지 못한 이미지를 찾아오도록, 생성 모델이 부족한 지식을 보완하는 이미지 찾아오도록 함 clip에서 원하는 이미지만 가져오면 그냥 비슷한 샘플이 뽑힐 것이기 때문이다.


3.2. 실제 객체 기반 검색 증강 생성 (Real-object-based Retrieval-augmented Generation)
reflective retriever를 기반으로, 우리는 이후에 텍스트 프롬프트 𝑇에 따라 생성기에 입력될 실제 객체 기반의 보강 이미지 I ref(1개)를 검색
텥스트 프롬프트와 방금 검색한 이미지 함께 사용해서 최종ㅇ 이미지 생성 (G는 텍스트 투 이미지 생성기임)
1. 오토레그레시브 모델 (Emu, OmniGen 등)
이 모델들은 원래부터 이미지 조건을 인풋으로 함께 넣을 수 있도록 설계됨.
2. Diffusion 모델 (SD V2.1, SD-XL, /dit기반 - SD V3, Flux 등)
이들은 원래 텍스트만 입력받는 구조이기 때문에,
추가 조건을 입력하려면 ControlNet과 같은 보조 네트워크(branch)가 필요


질문: ar방식의 토큰와이즈 이미지 생성 모델에서 이미지 컨텍스트 제공 시, 결과물이 좀더 의미 있는지(그 이미지 레퍼런스한 이미지를 생성하는지)
=>특히 디퓨전 기반 모델보다 효과 있었던거 보면 ar 기반 방식에서의 컨텍스트 처리가 매우 효율적인듯
